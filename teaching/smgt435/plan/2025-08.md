
# SMGT 435: Baseball Analytics

## 2025-08-25

7:00-7:05 Introductions (favorite baseball team, career aspirations)
- Discuss Dodgers/Padres series
- Discuss Padres/Mariners series (upcoming)

7:05-7:05 Randomly assign students to tables
- Create a question scoreboard

7:05-7:10 Syllabus review
- MLB club interview assessment
- MLB club project partnership

7:10-7:25 Pythagorean formula discussion, part 1
- 1 minute think
- 5 minutes discuss at tables
- 9 minutes large group discussion
1. Why is the Pythagorean formula important?
2. What are some reasons a team might truly be better than their Pythagorean record suggets?
3. If a team plays 10 games, what do you think will be more predictive of their future record: Pythag W\% or actual W\%? If the team plays 10 million games? At how many games do you switch from preferring Pythag W\% to actual W\%?

7:25-7:40 Lesson on regression to the mean vis-a-vis Pythagorean record
- Don't derive the correlation result; just present it

7:40-7:55 Pythagorean formula discussion, part 2
- Ample time for questions about regression to the mean model
- What MLB teams have most underperformed or overperformed their Pythagorean records this season? What are the implications of this observation?

7:55-8:00 Start Colab notebook
- test out Colab's AI feature

- Ground rules for R days:
  - Save a copy to your drive
  - Runtime -> Change Runtime Type -> R
  - I think there's a natural tendency to think that if you're struggling or confused, it's your fault, and that can make it more difficult to ask questions. I encourage you to raise your hand a lot when you feel lost. Right now is the opportunity for me to provide that instruction to you.

8:00-8:05 Break

8:05-9:25 Pythagorean formula Colab notebook

9:25-9:30 Exit ticket (3141)

Reflections
- I didn't provide a convincing argument that you should prefer Pythag over actual W% in a 10-game sample
- 2.5 hour class is tough, but students gave it a good effort on engagement
- Students were most engaged when we pulled up the actual baseball standings on FanGraphs
  - Good to make the concepts more concreate with real-life data

Subjective Rating 3/5

Student Interest      4.57/5
Student Understanding 3.85/5


## 2025-09-08

Notable comments from last class:

7:00-7:05 Discuss Blue Jays/Yankees series, Tigers/Yankees series

7:05 divide students into tables

7:05-7:15 Discuss confusions from last class
- What exactly is bootstrapping?
- Can I prove that Pythag is preferred in a 10-game sample?
- Start by writing down the model again
  - Explain the connection between this and linear regression
  - Explain the concept of a "multilevel" model
- Conceptualizing noise and signal variance

7:15-7:30 Discussion 1
1. What are the advantages and disadvantages of RE24 and LW relative to each other?
2. If you were creating a WAR metric, which would you use as the basis for batter evaluation?
3. What reasons might the residual RE24 - LW reflect true talent rather than luck?

7:30-7:40 Table Exercises 1
1. According to the FanGraphs Major League Leaders page for batting, who has the highest RE24 in the current season? Who has the highest LW?
2. According to the FanGraphs projected standings for the current season, which team has the best BaseRuns record? What is the difference between BaseRuns record and PythagenPat record?

7:40-7:50 Open to questions about RE24/LW and about the model for regression to the mean
- Write the model and the formula for regression to the mean on the board

7:50-8:00 Table Exercises 2
1. Suppose that the "true talent" of the residual RE24 -- LW for MLB batters is normally distributed with mean zero and *standard deviation* 0.02. Suppose further that the noise variance of observed performance is $0.2/n$, where $n$ is the number of plate appearances observed. If a batter accumulates 30 LW and 60 RE24 over 1,000 plate appearances, what is the posterior mean of their "true talent" residual per plate appearance (RE24 -- LW)/$n$?

8:00-8:05 Introduce Colab notebook

8:05-8:10 Break

8:10-9:25 Students work on Colab notebook

9:25-9:30 Exit ticket (5926)

Reflections
- Discussions of the previous class ran a bit long (~30 minutes)
- Otherwise, the students seemed pretty engaged today

Subjective Rating 4/5

Student Interest        4.88/5
Student Understanding   3.78/5


## 2025-09-15

- When we say "luck" does it just refer to all noise? Like do luck and clutch mean the same thing in terms of noise, or is there a reason why we assume luck over clutch? Also, why do we not assume clutch is actually skill?

- I think the Monday evening time made me lose focus at certain points, I think I just got caught up in all the terminologies and formulas of the modeling, and am still a bit confused about the interaction between the noise and signal variances and how they impact each other.¬†
- I feel like I keep confusing signal and noise variance and don't really know how to derive it. I was confused for part 2.

- How do we get the weights on Zj and 0?

- Maybe we went over this in class and I missed it, but I would love to see a mathematical proof of why LW is better than RE24. Intuitively it makes sense but it would be cool if it could be proved - if even possible.

7:00 Remind students about internships!

7:00-7:20 Write the model on the board and discuss exit ticket questions

7:20-7:35 Discussion 1
- Find the Baseball Savant player batting leaderboard. Who is leading the league in xwOBA? Who has the biggest gap between their wOBA and their xwOBA?
- What is the relationship between xwOBA (from Baseball Savant) and xLW3 (from the lecture notes)?
- Why might a batter's true-talent LW on batted balls be higher than their true-talent xLW3?

7:35-7:50 Question Game (review batted ball outcome model lecture notes)

7:50-8:05 Discussion 2
- Suppose that the true talent of the residual LW -- xLW3 for MLB batters is normally distributed with mean zero and standard deviation 0.02. Suppose further that the noise variance of observed performance is 0.2 / n, where n is the number of plate appearances observed. If a batter accumulates 20 xLW3 and 60 LW over 500 plate appearances, what is the posterior mean of their "true talent" residual per plate appearance (LW -- xLW3) / n?
- Which do you think is the best metric to evaluate batters: xLW3, xLW2 or xLW1?

8:05 Discuss homework #1

8:05-8:10 Introduce Colab Notebook

8:10-8:15 Break

8:15-9:25 Students work on Colab notebook at their own pace

9:25-9:30 Exit ticket (5358)

Reflections
- Today seemed particularly difficult to get the students engaged with questions, not sure why

Subjective Rating 3/5

Student Interest      4.57/5
Student Understanding 4.29/5

Reasons why students were quiet:
- I mostly don't know what to ask yet. I want to hear you cover some material first to see what makes sense to me or confuses me further and then ask.
- Personally, I tend to be quiet because I don't even know what to ask, but I don't know if the same applies to the rest of the class
- also for discussion I feel like I participate when I'm confident in my answer, but often the questions are a bit dense/difficult so I just don't feel super confident that I'm right and thus don't really speak up every time.
- I didn't ask any questions during the discussion portion of the lecture notes because I felt that I understood the lecture notes well from reading them before class
- I thought I understood the material decently well this week, I didn't ask any questions because I thought I understood xLW1, xLW2, xLW3 pretty well, and I didn't really have any questions until certain parts of the R tutorial.


## 2025-09-22

- im so curious how you generate your exit codes. is it random? is there a method? do we get to know

7:00-7:05 Cold Open
- Highlight latest internships
- Discuss lone question from last time

7:05-7:10 Re-assign tables for Unit #2

7:10-7:25 Discussion #1
- Jesus Luzardo
  - 14-7, 4.08 ERA, 3.01 FIP, 176.2 IP, 4.8 fWAR, 3.6 rWAR
- Freddy Peralta
  - 17-6, 3.61 ERA, 2.65 FIP, 169.2 IP, 3.6 fWAR, 5.4 rWAR
- Which player would you rank higher on your Cy Young ballot for 2025?
- Which player would you rather have on your team in 2026?

7:25-7:45 Introduce BABIP, FIP and DIPS
- What do you know about BABIP? (it's noisy)
  - What implications does this have for evaluating batters?
    - Connect it to RE24 -> LW -> xLW3 -> xLW2 -> xLW1
  - Discuss how we use the Bayesian model from class to answer the question: How much is BABIP luck?
    - Connect the model to the lme4::lmer code we use to estimate it
  - What implications does this have for evaluating pitchers?
- DIPS = Defense-Independent Pitching Statistics
- FIP = (13 * HR + 3 * (BB + HBP) - 2 * K) / IP
  - Due to Voros McCracken (early 2000s)
  - Discuss how we'll use the model to estimate how much weight to put on each outcome for pitchers

7:45-8:00 Discussion #2
- Some pitchers are known for consistently outperforming the league-average BABIP. Do you think this reflects true skill, or could it be explained by other factors (e.g., defense, park effects, randomness)?
- What are some limitations of FIP as a measure of pitcher performance? In what types of situations might ERA or another stat give us better information?
- Imagine you wanted to extend the DIPS framework with modern tracking data (e.g., Statcast). What new variables might help separate pitcher skill from randomness on balls in play?

8:00-8:05 Introduce BABIP/FIP/DIPS R tutorial

8:05-8:10 Break

8:10-9:20 Students work on BABIP/FIP/DIPS R tutorial

9:20-9:30 Course Eval #1 (7495)

Reflections
- I should really refrain from sharing my opinions on open-ended discussion questions
- R tutorial was more quiet than usual, but it seemed students made good progress

Subjective Rating 3/5

Course Eval Results
Conceptual Discussions  4.29/5
R Tutorials             4.00/5
Assignment #1           4.29/5
Assignment #1 hours     6.8 +/- 2.8

## 2025-09-29

7:00-7:05 Discuss Game 162 and the playoffs

7:05-7:10 Debrief Course Eval #1
- 4/7 students cited the Monday evening class time as a problem
- "I wish that we got to see the concepts we learn applied to real life examples outside of the R tutorials because I think it would make them easier to conceptualize."
- "One thing that I think could be improved is using as many current-day MLB examples as possible."
- "One thing I would appreciate is maybe a checkin as a class within the R tutorial time. I remember in your previous class, you would ask students how they completed a specific exercise. I am not sure if this would contrary to the goal you have for us when completing the exercises and I know that we all go at different paces. But maybe just at least verifying some of the numbers at the end of class."
- "The math is just difficult for me to grasp. I can fundamentally understand what is happening, but if I had to do the math or proof on my own I know that I wouldn't be able to. It's mostly a me problem."
- "It might just be me but the pre-class readings are sometimes a bit confusing."
- "I wish there was a bit of a tutorial or at least an introduction about random forest models and either GAM or xGBoost, because while I have used them before, I found it to be a little difficult to create those models for assignment one where they could actually be used accurately and effectively. Maybe previewing the assignments during class?"

7:10-7:30 Debrief Assignment #1
- If you had to fit a batted ball outcome model on a future assessment, what model would you use?
  - Why?
  - What are the strengths of random forest relative to linear model?
  - What are the strengths of GAM and gradient boosting relative to random forest?
- To what extent is it true that players' results can out-perform their batted ball trajectories?
- Misconceptions
  - R^2 = 0.14 indicates poor model fit
  - 99.8% noise for batted ball residuals

7:30-7:45 Discussion #1 (pitch value)

7:45-8:05 Solicit questions on pitch-level analysis

8:05-8:10 Discussion #2 (catcher framing)

8:10-8:15 Open R tutorial (pitch-level analysis), start installing lme4

8:15-8:20 Break

8:20-8:25 Preview Exercises #1-#3

8:25-9:25 R tutorial (pitch-level analysis)
- Write out a schedule of when each solution will be posted
- Just post the solution, announce it, do not discuss further
- When going around, ask students to show me what they did in their most recent exercise
  - This helps get them talking

9:25-9:30 Exit ticket (9793)

Reflections
- Offering Hi-Chews really lifted everyone's spirits
- Discussing the lecture notes on the whiteboard was a good idea
- I nailed the cadence of the R tutorial this time
  - I scheduled (on whiteboard) when I would paste in the solutions to each exercise

Subjective Rating 5/5

Student Interest      4.71/5
Student Understanding 4.57/5

- I dont think so, just to comment. I will say I feel way less confused than I do previous lectures. I feel that all the new additions, from the hi-chews to the updated R tutorial/check ins to the breakdown of the lecture notes made class a lot better and I think everyone felt more attentive.


## 2025-10-06

7:00-7:05 Talk about postseason

7:05-7:10 Review questions from last exit ticket
- I am a little unsure about what Run Value is and how RV < 0 is a below average pitch.
- Still not sure that count makes a ton of sense to be using for value, I would like to imagine there is a more robust/sound method. I feel like that would just be really noisy and very dependent on umpires, but idk baseball like that so I'm probably wrong. I would imagine there shouldn't technically be a difference in called strike probability in a 1-2 count versus a 2-1 count

7:10-7:25 Discussion

7:25-7:55 Pitch tracking lecture
- Just covering the highlights and soliciting questions

7:55-8:00 Break

8:00-8:10 Preview R tutorial

8:10-9:15 R tutorial (pitch outcome model)
- 8:20 Reveal Solution #1
- 8:30 Reveal Solution #2
- 8:40 Reveal Solution #3
- 8:50 Reveal Solution #4
- 9:00 Reveal Solution #5
- 9:05-9:15 Discuss takeaways

9:15-9:25 Preview Assignment #2

9:25-9:30 Exit ticket (2384)

Reflections
- I was sick today (wore a mask), and it was a struggle

Subjective Rating 2/5

Student Interest      4.50/5
Student Understanding 3.63/5 

## 2025-10-20

7:00-7:05 Discuss postseason

7:05-7:10 Discuss outstanding questions from last exit ticket

7:10-7:25 Warmup Discussion

7:25-7:55 "Stuff" lecture

7:55-8:10 Discussion

8:10-8:15 Break

8:15-8:20 Preview R Tutorial

8:20-9:20 R Tutorial
- 8:35 Post Solution #1
- 8:45 Post Solution #2
- 8:55 Post Solution #3
- 9:05 Post Solution #4
- 9:15 Post Solution #5

9:20-9:25 Recap R Tutorial

9:25-9:30 Exit ticket (8389)
